@misc{dehghaniPatchPackNaViT2023,
  title = {Patch n' {{Pack}}: {{NaViT}}, a {{Vision Transformer}} for Any {{Aspect Ratio}} and {{Resolution}}},
  shorttitle = {Patch n' {{Pack}}},
  author = {Dehghani, Mostafa and Mustafa, Basil and Djolonga, Josip and Heek, Jonathan and Minderer, Matthias and Caron, Mathilde and Steiner, Andreas and Puigcerver, Joan and Geirhos, Robert and Alabdulmohsin, Ibrahim and Oliver, Avital and Padlewski, Piotr and Gritsenko, Alexey and Lu{\v c}i{\'c}, Mario and Houlsby, Neil},
  year = 2023,
  month = jul,
  number = {arXiv:2307.06304},
  eprint = {2307.06304},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.06304},
  urldate = {2026-01-26},
  abstract = {The ubiquitous and demonstrably suboptimal choice of resizing images to a fixed resolution before processing them with computer vision models has not yet been successfully challenged. However, models such as the Vision Transformer (ViT) offer flexible sequence-based modeling, and hence varying input sequence lengths. We take advantage of this with NaViT (Native Resolution ViT) which uses sequence packing during training to process inputs of arbitrary resolutions and aspect ratios. Alongside flexible model usage, we demonstrate improved training efficiency for large-scale supervised and contrastive image-text pretraining. NaViT can be efficiently transferred to standard tasks such as image and video classification, object detection, and semantic segmentation and leads to improved results on robustness and fairness benchmarks. At inference time, the input resolution flexibility can be used to smoothly navigate the test-time cost-performance trade-off. We believe that NaViT marks a departure from the standard, CNN-designed, input and modelling pipeline used by most computer vision models, and represents a promising direction for ViTs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/anantajit/Zotero/storage/WSA9UT56/Dehghani et al. - 2023 - Patch n' Pack NaViT, a Vision Transformer for any Aspect Ratio and Resolution.pdf;/home/anantajit/Zotero/storage/CTEDU2VK/2307.html}
}

@article{kokocinska-kusiakCanineOlfactionPhysiology2021,
  title = {Canine {{Olfaction}}: {{Physiology}}, {{Behavior}}, and {{Possibilities}} for {{Practical Applications}}},
  shorttitle = {Canine {{Olfaction}}},
  author = {{Kokoci{\'n}ska-Kusiak}, Agata and Woszczy{\l}o, Martyna and Zybala, Miko{\l}aj and Maciocha, Julia and Bar{\l}owska, Katarzyna and Dzi{\k e}cio{\l}, Micha{\l}},
  year = 2021,
  month = aug,
  journal = {Animals : an Open Access Journal from MDPI},
  volume = {11},
  number = {8},
  pages = {2463},
  issn = {2076-2615},
  doi = {10.3390/ani11082463},
  urldate = {2026-01-26},
  abstract = {Simple Summary Dogs have an extraordinary olfactory capability, which far exceeds that of humans. Dogs' sense of smell seems to be the main sense, allowing them to not only gather both current and historical information about their surrounding environment, but also to find the source of the smell, which is crucial for locating food, danger, or partners for reproduction. Dogs can be trained by humans to use their olfactory abilities in a variety of fields, with a detection limit often much lower than that of sophisticated laboratory instruments. The specific anatomical and physiological features of dog olfaction allow humans to achieve outstanding results in the detection of drugs, explosives, and different illnesses, such as cancer, diabetes, or infectious disease. This article provides an overview of the anatomical features and physiological mechanisms involved in the process of odor detection and identification, as well as behavioral aspects of canine olfaction and its use in the service of humans in many fields. Abstract Olfaction in dogs is crucial for gathering important information about the environment, recognizing individuals, making decisions, and learning. It is far more specialized and sensitive than humans' sense of smell. Using the strength of dogs' sense of smell, humans work with dogs for the recognition of different odors, with a precision far exceeding the analytical capabilities of most modern instruments. Due to their extremely sensitive sense of smell, dogs could be used as modern, super-sensitive mobile area scanners, detecting specific chemical signals in real time in various environments outside the laboratory, and then tracking the odor of dynamic targets to their source, also in crowded places. Recent studies show that dogs can detect not only specific scents of drugs or explosives, but also changes in emotions as well as in human cell metabolism during various illnesses, including COVID-19 infection. Here, we provide an overview of canine olfaction, discussing aspects connected with anatomy, physiology, behavioral aspects of sniffing, and factors influencing the olfactory abilities of the domestic dog (Canis familiaris).},
  pmcid = {PMC8388720},
  pmid = {34438920},
  file = {/home/anantajit/Zotero/storage/C8G6KB2N/Kokoci≈Ñska-Kusiak et al. - 2021 - Canine Olfaction Physiology, Behavior, and Possibilities for Practical Applications.pdf}
}

@article{krupnikMultiAgentReinforcementLearning,
  title = {Multi-{{Agent Reinforcement Learning}} with {{Multi-Step Generative Models}}},
  author = {Krupnik, Orr and Mordatch, Igor and Tamar, Aviv},
  abstract = {We consider model-based reinforcement learning (MBRL) in 2-agent, high-fidelity continuous control problems -- an important domain for robots interacting with other agents in the same workspace. For non-trivial dynamical systems, MBRL typically suffers from accumulating errors. Several recent studies have addressed this problem by learning latent variable models for trajectory segments and optimizing over behavior in the latent space. In this work, we investigate whether this approach can be extended to 2-agent competitive and cooperative settings. The fundamental challenge is how to learn models that capture interactions between agents, yet are disentangled to allow for optimization of each agent behavior separately. We propose such models based on a disentangled variational auto-encoder, and demonstrate our approach on a simulated 2-robot manipulation task, where one robot can either help or distract the other. We show that our approach has better sample efficiency than a strong model-free RL baseline, and can learn both cooperative and adversarial behavior from the same data.},
  langid = {english},
  file = {/home/anantajit/Zotero/storage/9WUFIA94/Krupnik et al. - Multi-Agent Reinforcement Learning with Multi-Step Generative Models.pdf}
}

@article{quignonComparisonCanineHuman2003,
  title = {Comparison of the Canine and Human Olfactory Receptor Gene Repertoires},
  author = {Quignon, Pascale and Kirkness, Ewen and Cadieu, Edouard and Touleimat, Nizar and Guyon, Richard and Renier, Corinne and Hitte, Christophe and Andr{\'e}, Catherine and Fraser, Claire and Galibert, Francis},
  year = 2003,
  journal = {Genome Biology},
  volume = {4},
  number = {12},
  pages = {R80},
  issn = {1474-7596},
  doi = {10.1186/gb-2003-4-12-r80},
  urldate = {2026-01-26},
  abstract = {In this study, 817 novel canine olfactory receptor (OR) sequences were identified, and 640 have been characterized. Of the 661 characterized OR sequences, representing half of the canine repertoire, 18\% are predicted to be pseudogenes, compared with 63\% in human and 20\% in mouse.},
  pmcid = {PMC329419},
  pmid = {14659017},
  file = {/home/anantajit/Zotero/storage/ERDJ8ILZ/Quignon et al. - 2003 - Comparison of the canine and human olfactory receptor gene repertoires.pdf}
}

@inproceedings{REALTIMESIMULATIONSOUND2006,
  title = {{{REAL-TIME SIMULATION OF SOUND SOURCE OCCLUSION}}:},
  shorttitle = {{{REAL-TIME SIMULATION OF SOUND SOURCE OCCLUSION}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Signal Processing}} and {{Multimedia Applications}}},
  year = 2006,
  pages = {193--199},
  publisher = {{SciTePress - Science and and Technology Publications}},
  address = {Set\'ubal, Portugal},
  doi = {10.5220/0001571501930199},
  urldate = {2026-01-26},
  abstract = {Sound source occlusion occurs when the direct path from a sound source to a listener is blocked by an intervening object. Currently, a variety of methods exist for modeling sound source occlusion. These include finite element and boundary element methods, as well as methods based on time-domain models of edge diffraction. At present, the high computational requirements of these methods precludes their use in real-time environments. In the case of real-time geometric room acoustic methods (e.g. the image method, ray tracing), the model of sound propagation employed makes it difficult to incorporate wave-related effects such as occlusion. As a result, these methods generally do not incorporate sound source occlusion. The lack of a suitable sound source occlusion method means that developers of real-time virtual environments (such as computer games) have generally either ignored this phenomenon or used rudimentary and perceptually implausible approximations. A potential solution to this problem is the use of shadow algorithms from computer graphics. These algorithms can provide a way to efficiently simulate sound source occlusion in real-time and in a physically plausible manner. Two simulation prototypes are presented, one for fixed-position sound sources and another for moving sound sources.},
  isbn = {978-972-8865-64-1},
  langid = {english},
  file = {/home/anantajit/Zotero/storage/SISCCRZP/2006 - REAL-TIME SIMULATION OF SOUND SOURCE OCCLUSION.pdf}
}

@article{rigolliLearningPredictTarget2022,
  title = {Learning to Predict Target Location with Turbulent Odor Plumes},
  author = {Rigolli, Nicola and Magnoli, Nicodemo and Rosasco, Lorenzo and Seminara, Agnese},
  editor = {Goldstein, Raymond E and Walczak, Aleksandra M},
  year = 2022,
  month = aug,
  journal = {eLife},
  volume = {11},
  pages = {e72196},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.72196},
  urldate = {2026-01-26},
  abstract = {Animal behavior and neural recordings show that the brain is able to measure both the intensity and the timing of odor encounters. However, whether intensity or timing of odor detections is more informative for olfactory-driven behavior is not understood. To tackle this question, we consider the problem of locating a target using the odor it releases. We ask whether the position of a target is best predicted by measures of timing vs intensity of its odor, sampled for a short period of time. To answer this question, we feed data from accurate numerical simulations of odor transport to machine learning algorithms that learn how to connect odor to target location. We find that both intensity and timing can separately predict target location even from a distance of several meters; however, their efficacy varies with the dilution of the odor in space. Thus, organisms that use olfaction from different ranges may have to switch among different modalities. This has implications on how the brain should represent odors as the target is approached. We demonstrate simple strategies to improve accuracy and robustness of the prediction by modifying odor sampling and appropriately combining distinct measures together. To test the predictions, animal behavior and odor representation should be monitored as the animal moves relative to the target, or in virtual conditions that mimic concentrated vs dilute environments.},
  keywords = {fluid dynamics,machine learning,olfaction,prediction},
  file = {/home/anantajit/Zotero/storage/DVYHIEDL/Rigolli et al. - 2022 - Learning to predict target location with turbulent odor plumes.pdf}
}
